{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163283, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_wafer</th>\n",
       "      <th>record</th>\n",
       "      <th>sensor_6</th>\n",
       "      <th>sensor_7</th>\n",
       "      <th>sensor_8</th>\n",
       "      <th>sensor_11</th>\n",
       "      <th>sensor_12</th>\n",
       "      <th>sensor_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1549_1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-11</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1549_1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-11</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1549_1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1549_1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>-11</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1549_1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>477</td>\n",
       "      <td>2</td>\n",
       "      <td>-11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  run_wafer  record  sensor_6  sensor_7  sensor_8  sensor_11  sensor_12  \\\n",
       "0    1549_1       1         3        24        10          2        -11   \n",
       "1    1549_1       2         3        25        10          2        -11   \n",
       "2    1549_1       3         3        24        10          2        -11   \n",
       "3    1549_1       4         3        25        10          2        -11   \n",
       "4    1549_1       5         3        25       477          2        -11   \n",
       "\n",
       "   sensor_15  \n",
       "0         -1  \n",
       "1         -1  \n",
       "2          0  \n",
       "3         -1  \n",
       "4          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#basic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "#sax\n",
    "from saxpy.sax import ts_to_string\n",
    "from saxpy.alphabet import cuts_for_asize\n",
    "from saxpy.paa import paa\n",
    "#sklearn\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix,roc_curve, auc\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "#關掉warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#draw\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "original_df = pd.read_excel(\"Data\\\\sensor.xlsx\")\n",
    "is_abormal = pd.read_excel(\"Data\\\\is_abormal.xlsx\")\n",
    "\n",
    "print(original_df.shape)\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sensor_6     0\n",
       "sensor_7     0\n",
       "sensor_8     0\n",
       "sensor_11    0\n",
       "sensor_12    0\n",
       "sensor_15    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = original_df.copy()\n",
    "scaler = StandardScaler()\n",
    "sensors = ['sensor_6', 'sensor_7', 'sensor_8', 'sensor_11','sensor_12', 'sensor_15']\n",
    "for run in df.run_wafer.unique():\n",
    "    mask = df[\"run_wafer\"] == run\n",
    "    df.loc[mask,sensors] = scaler.fit_transform(df.loc[mask,sensors].values)\n",
    "\n",
    "(df.groupby(\"run_wafer\").mean()[sensors]>0.0000001 ).sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用PAA降維"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121.19681215286255\n",
      "   sensor_6  sensor_7  sensor_8  sensor_11  sensor_12  sensor_15 run_wafer\n",
      "0 -1.585434  1.260826 -2.105993  -1.465557  -1.566471   1.487811    1549_1\n",
      "1 -1.585434  1.261043 -2.095084  -1.465557  -1.566471   1.498482    1549_1\n",
      "2 -1.585434  1.260935 -1.303938  -1.465557  -1.566471   1.509153    1549_1\n",
      "3 -1.585434  1.260499  0.637462  -1.465557  -1.566471   1.509153    1549_1\n",
      "4 -1.585434  1.260826  1.478703  -1.465557  -1.566471   1.509153    1549_1\n"
     ]
    }
   ],
   "source": [
    "sensors = ['sensor_6', 'sensor_7', 'sensor_8', 'sensor_11','sensor_12', 'sensor_15']\n",
    "ratio = 2\n",
    "\n",
    "s = time.time()\n",
    "d = defaultdict(list)\n",
    "for run in df.run_wafer.unique():\n",
    "    tmp = df[df[\"run_wafer\"] == run]\n",
    "    for sensor in sensors:\n",
    "        compress = paa(tmp[sensor].values, tmp.shape[0]//ratio).tolist()\n",
    "        d[sensor].extend(compress)\n",
    "    d[\"run_wafer\"].extend([run]*len(compress))\n",
    "print(time.time()-s) \n",
    "\n",
    "new_df = pd.DataFrame(d)\n",
    "print(new_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算每一筆紀錄的統計量\n",
    "1. max\n",
    "2. min\n",
    "3. 25%\n",
    "4. 50%\n",
    "5. 75%\n",
    "6. mean\n",
    "7. std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_wafer</th>\n",
       "      <th>max_6</th>\n",
       "      <th>min_6</th>\n",
       "      <th>25%_6</th>\n",
       "      <th>50%_6</th>\n",
       "      <th>75%_6</th>\n",
       "      <th>mean_6</th>\n",
       "      <th>std_6</th>\n",
       "      <th>max_7</th>\n",
       "      <th>min_7</th>\n",
       "      <th>...</th>\n",
       "      <th>75%_12</th>\n",
       "      <th>mean_12</th>\n",
       "      <th>std_12</th>\n",
       "      <th>max_15</th>\n",
       "      <th>min_15</th>\n",
       "      <th>25%_15</th>\n",
       "      <th>50%_15</th>\n",
       "      <th>75%_15</th>\n",
       "      <th>mean_15</th>\n",
       "      <th>std_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1549_1</td>\n",
       "      <td>0.820290</td>\n",
       "      <td>-1.587454</td>\n",
       "      <td>-1.499202</td>\n",
       "      <td>0.608105</td>\n",
       "      <td>0.611391</td>\n",
       "      <td>-3.951088e-16</td>\n",
       "      <td>0.979275</td>\n",
       "      <td>3.005177</td>\n",
       "      <td>-0.696804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580351</td>\n",
       "      <td>-1.169000e-15</td>\n",
       "      <td>0.980410</td>\n",
       "      <td>1.509153</td>\n",
       "      <td>-0.791218</td>\n",
       "      <td>-0.769720</td>\n",
       "      <td>-0.718248</td>\n",
       "      <td>1.427826</td>\n",
       "      <td>-3.526591e-16</td>\n",
       "      <td>0.990688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1549_2</td>\n",
       "      <td>0.847689</td>\n",
       "      <td>-1.500817</td>\n",
       "      <td>-1.496973</td>\n",
       "      <td>0.634670</td>\n",
       "      <td>0.637641</td>\n",
       "      <td>8.913058e-16</td>\n",
       "      <td>0.985517</td>\n",
       "      <td>1.481557</td>\n",
       "      <td>-0.745496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.611518</td>\n",
       "      <td>3.690319e-16</td>\n",
       "      <td>0.987463</td>\n",
       "      <td>1.449295</td>\n",
       "      <td>-0.812871</td>\n",
       "      <td>-0.791119</td>\n",
       "      <td>-0.719628</td>\n",
       "      <td>1.427543</td>\n",
       "      <td>9.225797e-16</td>\n",
       "      <td>0.990544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1549_4</td>\n",
       "      <td>0.905271</td>\n",
       "      <td>-1.460575</td>\n",
       "      <td>-1.457195</td>\n",
       "      <td>0.654202</td>\n",
       "      <td>0.656616</td>\n",
       "      <td>-3.330669e-16</td>\n",
       "      <td>0.990588</td>\n",
       "      <td>1.555107</td>\n",
       "      <td>-0.795116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645328</td>\n",
       "      <td>6.167906e-18</td>\n",
       "      <td>0.992692</td>\n",
       "      <td>1.442394</td>\n",
       "      <td>-0.921343</td>\n",
       "      <td>-0.769290</td>\n",
       "      <td>-0.741644</td>\n",
       "      <td>1.414748</td>\n",
       "      <td>3.330669e-16</td>\n",
       "      <td>0.995215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1549_6</td>\n",
       "      <td>0.884996</td>\n",
       "      <td>-1.444958</td>\n",
       "      <td>-1.441226</td>\n",
       "      <td>0.661702</td>\n",
       "      <td>0.664989</td>\n",
       "      <td>5.119362e-16</td>\n",
       "      <td>0.981266</td>\n",
       "      <td>1.398198</td>\n",
       "      <td>-0.779656</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618106</td>\n",
       "      <td>-6.137066e-16</td>\n",
       "      <td>0.984316</td>\n",
       "      <td>1.388516</td>\n",
       "      <td>-0.858014</td>\n",
       "      <td>-0.816411</td>\n",
       "      <td>-0.766130</td>\n",
       "      <td>1.367930</td>\n",
       "      <td>-4.502571e-16</td>\n",
       "      <td>0.991135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1549_7</td>\n",
       "      <td>0.842025</td>\n",
       "      <td>-1.499659</td>\n",
       "      <td>-1.496977</td>\n",
       "      <td>0.635691</td>\n",
       "      <td>0.637651</td>\n",
       "      <td>-1.351032e-15</td>\n",
       "      <td>0.985491</td>\n",
       "      <td>1.606777</td>\n",
       "      <td>-0.769984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.718632</td>\n",
       "      <td>-2.408089e-16</td>\n",
       "      <td>0.989204</td>\n",
       "      <td>1.433565</td>\n",
       "      <td>-0.867655</td>\n",
       "      <td>-0.792259</td>\n",
       "      <td>-0.748017</td>\n",
       "      <td>1.411485</td>\n",
       "      <td>-5.691848e-16</td>\n",
       "      <td>0.990884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  run_wafer     max_6     min_6     25%_6     50%_6     75%_6        mean_6  \\\n",
       "0    1549_1  0.820290 -1.587454 -1.499202  0.608105  0.611391 -3.951088e-16   \n",
       "1    1549_2  0.847689 -1.500817 -1.496973  0.634670  0.637641  8.913058e-16   \n",
       "2    1549_4  0.905271 -1.460575 -1.457195  0.654202  0.656616 -3.330669e-16   \n",
       "3    1549_6  0.884996 -1.444958 -1.441226  0.661702  0.664989  5.119362e-16   \n",
       "4    1549_7  0.842025 -1.499659 -1.496977  0.635691  0.637651 -1.351032e-15   \n",
       "\n",
       "      std_6     max_7     min_7  ...    75%_12       mean_12    std_12  \\\n",
       "0  0.979275  3.005177 -0.696804  ...  0.580351 -1.169000e-15  0.980410   \n",
       "1  0.985517  1.481557 -0.745496  ...  0.611518  3.690319e-16  0.987463   \n",
       "2  0.990588  1.555107 -0.795116  ...  0.645328  6.167906e-18  0.992692   \n",
       "3  0.981266  1.398198 -0.779656  ...  0.618106 -6.137066e-16  0.984316   \n",
       "4  0.985491  1.606777 -0.769984  ...  0.718632 -2.408089e-16  0.989204   \n",
       "\n",
       "     max_15    min_15    25%_15    50%_15    75%_15       mean_15    std_15  \n",
       "0  1.509153 -0.791218 -0.769720 -0.718248  1.427826 -3.526591e-16  0.990688  \n",
       "1  1.449295 -0.812871 -0.791119 -0.719628  1.427543  9.225797e-16  0.990544  \n",
       "2  1.442394 -0.921343 -0.769290 -0.741644  1.414748  3.330669e-16  0.995215  \n",
       "3  1.388516 -0.858014 -0.816411 -0.766130  1.367930 -4.502571e-16  0.991135  \n",
       "4  1.433565 -0.867655 -0.792259 -0.748017  1.411485 -5.691848e-16  0.990884  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#將不同sensor攤開聚合計算\n",
    "def flattern(df):\n",
    "    statistics = defaultdict(list) \n",
    "    for run in df[\"run_wafer\"].unique():\n",
    "        sta = df[df[\"run_wafer\"]==run].describe()\n",
    "        statistics[\"run_wafer\"].append(run)\n",
    "        for sensor in [\"sensor_6\",\"sensor_7\",\"sensor_8\",\"sensor_11\",\"sensor_12\",\"sensor_15\"]:\n",
    "            th = sensor.split(\"_\")[-1]\n",
    "            statistics[f\"max_{th}\"].append(sta.loc['max',sensor])\n",
    "            statistics[f\"min_{th}\"].append(sta.loc[\"min\",sensor])\n",
    "            statistics[f\"25%_{th}\"].append(sta.loc[\"25%\",sensor])\n",
    "            statistics[f\"50%_{th}\"].append(sta.loc[\"50%\",sensor])\n",
    "            statistics[f\"75%_{th}\"].append(sta.loc[\"75%\",sensor])\n",
    "            statistics[f\"mean_{th}\"].append(sta.loc[\"mean\",sensor])\n",
    "            statistics[f\"std_{th}\"].append(sta.loc[\"std\",sensor])\n",
    "    return pd.DataFrame(statistics)\n",
    "\n",
    "#計算統計量\n",
    "df_sta = flattern(new_df)\n",
    "df_sta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross(models,X,y,cv):\n",
    "    d = {}\n",
    "    for model in models:\n",
    "        algorithm = str(model)[:str(model).find(\"(\")]\n",
    "        d[algorithm] = cross_validate(model,X,y,cv=cv)\n",
    "        d[algorithm][\"fit_time\"] = np.mean(d[algorithm][\"fit_time\"])\n",
    "        d[algorithm][\"score_time\"] = np.mean(d[algorithm][\"score_time\"])\n",
    "        d[algorithm][\"test_score\"] = np.mean(d[algorithm][\"test_score\"])  \n",
    "        y_pred = cross_val_predict(model, X, y, cv=cv)\n",
    "        d[algorithm][\"conf_mat\"] = confusion_matrix(y, y_pred)\n",
    "    return d\n",
    "\n",
    "df_merged = df_sta.merge(is_abormal,on=\"run_wafer\")\n",
    "y = df_merged[\"is_abnormal\"].values\n",
    "X = df_merged.drop([\"run_wafer\",\"is_abnormal\"],axis=1)\n",
    "RF_model = RandomForestClassifier(random_state = 0)\n",
    "xgb_model = XGBClassifier(random_state=0)\n",
    "svc_model = SVC(gamma='auto')\n",
    "score = cross([RF_model,xgb_model,svc_model],X,y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestClassifier': {'fit_time': 0.024325227737426756, 'score_time': 0.0015018463134765625, 'test_score': 0.9832485875706215, 'conf_mat': array([[1063,    4],\n",
      "       [  16,  111]], dtype=int64)}, 'XGBClassifier': {'fit_time': 0.40300090312957765, 'score_time': 0.002600836753845215, 'test_score': 0.9882768361581921, 'conf_mat': array([[1064,    3],\n",
      "       [  11,  116]], dtype=int64)}, 'SVC': {'fit_time': 0.017253637313842773, 'score_time': 0.0020904302597045898, 'test_score': 0.8986581920903955, 'conf_mat': array([[1067,    0],\n",
      "       [ 121,    6]], dtype=int64)}}\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算每筆sensor之間的距離\n",
    "1. 歐幾里得"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euclidean_distance(arr1,arr2):\n",
    "    return np.sqrt(sum(pow(arr1-arr2,2)))\n",
    "\n",
    "#將不同sensor攤開\n",
    "def cal_euclidean_distance_groupby_run_wafer(df):\n",
    "    dis = defaultdict(list) \n",
    "    for run in df[\"run_wafer\"].unique():\n",
    "        dis[\"run_wafer\"].append(run)\n",
    "        tmp = df[df[\"run_wafer\"] == run]\n",
    "        dis[\"dis_6_7\"].append(get_euclidean_distance(tmp[\"sensor_6\"].values,tmp[\"sensor_7\"].values))\n",
    "        dis[\"dis_6_8\"].append(get_euclidean_distance(tmp[\"sensor_6\"].values,tmp[\"sensor_8\"].values))\n",
    "        dis[\"dis_6_11\"].append(get_euclidean_distance(tmp[\"sensor_6\"].values,tmp[\"sensor_11\"].values))\n",
    "        dis[\"dis_6_12\"].append(get_euclidean_distance(tmp[\"sensor_6\"].values,tmp[\"sensor_12\"].values))\n",
    "        dis[\"dis_6_15\"].append(get_euclidean_distance(tmp[\"sensor_6\"].values,tmp[\"sensor_15\"].values))\n",
    "        \n",
    "        dis[\"dis_7_8\"].append(get_euclidean_distance(tmp[\"sensor_7\"].values,tmp[\"sensor_8\"].values))\n",
    "        dis[\"dis_7_11\"].append(get_euclidean_distance(tmp[\"sensor_7\"].values,tmp[\"sensor_11\"].values))\n",
    "        dis[\"dis_7_12\"].append(get_euclidean_distance(tmp[\"sensor_7\"].values,tmp[\"sensor_12\"].values))\n",
    "        dis[\"dis_7_15\"].append(get_euclidean_distance(tmp[\"sensor_7\"].values,tmp[\"sensor_15\"].values))\n",
    "        \n",
    "        dis[\"dis_8_11\"].append(get_euclidean_distance(tmp[\"sensor_8\"].values,tmp[\"sensor_11\"].values))\n",
    "        dis[\"dis_8_12\"].append(get_euclidean_distance(tmp[\"sensor_8\"].values,tmp[\"sensor_12\"].values))\n",
    "        dis[\"dis_8_15\"].append(get_euclidean_distance(tmp[\"sensor_8\"].values,tmp[\"sensor_15\"].values))\n",
    "        \n",
    "        dis[\"dis_11_12\"].append(get_euclidean_distance(tmp[\"sensor_11\"].values,tmp[\"sensor_12\"].values))\n",
    "        dis[\"dis_11_15\"].append(get_euclidean_distance(tmp[\"sensor_11\"].values,tmp[\"sensor_15\"].values))\n",
    "        \n",
    "        dis[\"dis_12_15\"].append(get_euclidean_distance(tmp[\"sensor_12\"].values,tmp[\"sensor_15\"].values))\n",
    "        \n",
    "    return pd.DataFrame(dis) \n",
    "\n",
    "df_dis = cal_euclidean_distance_groupby_run_wafer(new_df)\n",
    "df_merged = df_sta.merge(df_dis, on=\"run_wafer\")\n",
    "df_merged = df_merged.merge(is_abormal,on=\"run_wafer\")\n",
    "\n",
    "y = df_merged[\"is_abnormal\"].values\n",
    "X = df_merged.drop([\"run_wafer\",\"is_abnormal\"],axis=1)\n",
    "RF_model = RandomForestClassifier(random_state = 0)\n",
    "xgb_model = XGBClassifier(random_state=0)\n",
    "svc_model = SVC(gamma='auto')\n",
    "score = cross([RF_model,xgb_model,svc_model],X,y,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RandomForestClassifier': {'fit_time': 0.029525566101074218, 'score_time': 0.0014802217483520508, 'test_score': 0.9840395480225987, 'conf_mat': array([[1060,    7],\n",
      "       [  12,  115]], dtype=int64)}, 'XGBClassifier': {'fit_time': 0.5137918949127197, 'score_time': 0.002063941955566406, 'test_score': 0.9882627118644066, 'conf_mat': array([[1065,    2],\n",
      "       [  12,  115]], dtype=int64)}, 'SVC': {'fit_time': 0.01745030879974365, 'score_time': 0.0023001670837402345, 'test_score': 0.9513276836158193, 'conf_mat': array([[1064,    3],\n",
      "       [  55,   72]], dtype=int64)}}\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
